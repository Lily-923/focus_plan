## Task 4：自然语言处理（Natural Language Processing，NLP）

### [](https://d.jotang.club/t/topic/976#h-23)题目背景

-   笨小鸭从学校回来，哭着和妈妈说：“同学们都说我数学差，不和我玩“。
-   鸭妈妈叹了口气，说：“你同学真烦人 ![:roll_eyes:](https://d.jotang.club/images/emoji/apple/roll_eyes.png?v=12 ":roll_eyes:")。但妈妈给你讲个故事：从前有个人数学也很差，但他学习了 AI，自己训练了一个数学很厉害的 LLM，每次别人题还没看完，他就用 LLM 得到了正确答案。自此，再也没有人敢嘲笑他数学差，大家还都向他请教让模型变强的方法。你知道该怎么做了吧？”
-   笨小鸭若有所思地点点头，说：“明白了，我要做 LLM，训练出最厉害的模型堵住他们的嘴。”鸭妈妈欣慰地笑了。
-   自此，笨小鸭开始拼命学习。别人学微积分，他学 Transformer、Prompt；别人学线性代数，他学 RAG、CoT……毕业找工作时，他终于面进了一家叫鹅厂的公司，这里没有人关注他的数学成绩，只关心他能不能优化混元大模型。
-   笨小鸭终于意识到：原来我是一只鹅，鹅厂才是我该来的地方。

[![image](https://d.jotang.club/uploads/default/optimized/1X/cb2c00f4ad1751e54de24362ce46b0296328f52c_2_690x151.jpeg)](https://d.jotang.club/uploads/default/original/1X/cb2c00f4ad1751e54de24362ce46b0296328f52c.jpeg "image")

image1386×304 27.9 KB

### 完成题目

-   形式语言和自动机 
形式语言理论曾经是自然语言描述和分析的基础，自动机理论在自然语言的词法分析、拼写检查和短语识别等很多方面都有着广泛的用途。在深度学习兴起前，人们曾通过给形式语言构建编译器的方式进行自然语言处理。
    -   什么是形式语言？请简述其与自然语言的区别。
   形式语言是一种**用符号，规则以及逻辑结构来表达信息的语言**，有严格的定义与规范。例如布尔代数形式里面有∧,∨来表示逻辑与，逻辑或；计算机编程语言中用“if”表示条件语句，用“while”表示循环语句等。
   在形式上，自然语言由一组明确定义的符号和词汇构成，这些符号通常具有严格的数学或逻辑定义，但自然语言由丰富的词汇和语法构成，词汇量庞大且具有多种含义。例如，英语中的“run”可以表示“跑步”，“经营”，“流动”等意思。所以形式语言用于数学、逻辑、计算机科学等领域，强调**精确性和可操作性**；自然语言用于人类日常交流，文学创作，艺术表达等，强调表达的**灵活性和情感性**。
    -   形式语法有哪些定义和类型？
    形式语法的定义：形式语法G是一个四元组G=（N,Σ，P，S），N：非终结符的有限集合；Σ：终结符的有限集合；P：产生式的有限集合；S：起始符号。通过反复利用P中的规则，从S出发可以导出不含终结符的“句子”；所有句子的集合成为该语法生成的语言。记作L（G）。
    形式语法的四大类型：
    0型：可计算语言，例如图灵机；
    1型：上下文有关语言，例如线性有界自动机；
    2型：上下文无关语言，下推自动机；
    3型：正则语言，有限自动机。
    **从0-3型，能识别的语言越来越简单。**
    -   什么是自动机？自动机有哪些类型？在自然语言处理中有何应用？
    自动机就是一台**按照规则读取字符、变状态、给答案的“抽象机器”**。把输入当做一串字符，每读取一个字符就根据事先写好的“转移表”跳到下一个状态；读完之后，看落在那个终态就给出“拒绝/接受”或是其他输出。
    常见的类型：
         有限自动机（DFA/NFA），没有记忆，只靠当前状态，类比一个灯泡；
         下推自动机（PDA），加了一条栈，能记住括号。类比一个灯泡+一个栈；
         线性有界自动机（LBA），栈长度<=输入长度，带“尺子”。类比一个灯泡+一段“可擦写的胶带”；
         图灵机（TM），无限纸袋，想写就写。灯泡+无限长的纸带+万能橡皮。
     自动机在自然语言处理中可以进行**分词/语法分析**，**正则抽取**，**句法检查**，**状态转录机**，**语音解码**等。
   -   语料库与语言模型
    -   什么是语料库？它在自然语言处理中的作用是什么？
    语料库就是**按一定标准收集、清洗、标注的大规模真实语言数据集合**。机器学习模型要先利用语料库的资源学习上百万句中文，才能学会词法和语法。然后同一批数据集才能按照8:1：1分成训练集、验证集、测试集，用来打分、比性能。
    -   什么是语言模型（Language Model, LM）？语言模型试图解决什么问题？
    语言模型（LM）可以想象成一个**“文字接龙机器”**，它会思考“给定前面已经说过的内容，接下来最有可能说什么”，用来学会一个核心问题：**看到前面一串词之后，下一个词出现的概率是多大。**
    -   假设你正在设计一个自动补全系统，如何利用 n-gram 语言模型来预测下一个词？例如在输入法中，给定一个句子 `I want to eat __`，如何估计下一个词的概率？有哪些可能的问题（比如稀疏性、长距离依赖）？
    n-gram语言模型根据前面n个词来推测第n个词是什么。**先把训练文本中所有n个词连在一起出现的次数记下来，再用“相邻n-1个词后面某个词的总次数/这n-1个词的总次数”当概率，最后把每一步算出的概相乘**，就得到了整句话的概率。
     **稀疏性**：很多n-gram在训练里面没有见过。
     **长距离依赖**：只能看n-1个词，记不住整句。
    **内存爆炸**：n越大可能的组合指数型增长。
    -   请你使用 NLTK 自带的 Brown 语料库，每个句子都已经分词好（无需再分句）构建 unigram, bigram, trigram 语言模型，实现候选词预测功能（如输入 “I want to eat” → 返回 top-k 预测词）
    - ![输入图片说明](/imgs/2025-10-18/BsgdPZThpX6PHzVj.png)
-   为什么语言模型中需要使用平滑技术？请简要举例说明不平滑的风险。
   平滑技术遇到没有见到过的词组时，也会**把0的概率变成0.0X**，避免了因为模型**没有见过就把整句话概率压为0**的情况。如果没有平滑技术就会导致任何没有见过的词汇使得整句概率变成0，即使其余部分是合理的。
-   自然语言词嵌入
    -   什么是词向量？为什么我们需要用向量来表示词？
    词向量是把每个词语表示成一个**固定长度的实数向量**。计算机只能处理数字，无法直接处理文字。把词变成向量就让计算机更好的理解人类语言。
    -   one-hot 编码是什么？为什么使用 one-hot 编码来表示词语会导致维度灾难？
    one-hot编码是一种把离散的符号转换成二进制向量的最简单方法。假设词汇表大小为V，则每个词被表示成一个**V维的向量**，其中只有对应词的位置为1，其余位置全部为0.
    因为**词汇量=向量长度**。英语常用词10万-50万，甚至更大，所以导致特征维度极大且稀疏，计存储、泛化都变得十分困难。
    -   Word2Vec 提供了哪两种训练架构？分别是如何工作的？
    CBOW：利用上下文来预测中心词；
    Skip-gram:用中心词预测上下文。
    -   使用 `nltk.corpus.brown` 语料库构造训练数据，你也可以改成使用 `text8`，`gutenberg` 等公开语料（取决于训练规模），使用 Gensim 或手动实现 Skip-gram / CBOW，训练词向量，支持相似词查询等操作。
![输入图片说明](/imgs/2025-10-18/GFTEKixcNLfxK6D0.png)
-   大模型预训练和微调
    -   LLM 的训练通常分为哪两个阶段？他们之间有什么区别？所用数据有何不同？
    LLM的训练通常被分为**预训练**和**后训练**。预训练先让模型掌握通用语言规语常识与世界知识，形成基础能力，学习方式采用**自监督/无监督**，通常**全量训练**（对所有参数进行完整训练），需要GPU，时间较长。通常使用基座模型；后训练（微调）把通用机座适配到特定领域，使用**监督学习/强化学习**，可**全量也可高效微调**，所需GPU，时间更少，通常使用领域专用模型。
    预训练使用数据规模比后训练大得多，且数据来源于各个方面无人工标注，后训练的数据来源于任务专用科，有人工标注或人工-模型协同标注。
    -   有哪些微调方法？他们适用于什么场景？
    1.**全量微调**：所有权重都参与梯度更新，适用于数据量大、目标领域和预训练差异大、追求SOTA精度的模型。
    2.**参数高效微调**：在原权重旁加低秩矩阵AB，只训练AB，适用于数据较少/轻量级任务/个人显卡，边缘设备/极简风格。
-   自回归 AI 和 生成式 AI：文字生成
    -   什么是“自回归模型”？请写出其生成概率公式。
   自回归模型（AR）把序列生成看做**逐步条件概率的乘积**：每一步都把前面已生成的全部token当做条件来预测下一个token的概率，再从中采样得到新token，如此循环直到结束。
生成概率公式：对于长度为$T$的序列
$$
\mathbf{x} = (x_1, x_2, \dots, x_T)
$$，其联合概率为：
$$
P(x_1, x_2, \dots, x_T) = \prod_{t=1}^{T} P(x_t \mid x_1, x_2, \dots, x_{t-1})
$$ 
其中：Xt表示序列中的第t个词；
          X1，...Xt-1表示生成的上文；
           整个序列的联合概率等于每一步条件概率的乘积。
    - 为什么模型每一步只能生成一个词？为什么生成任务是逐词展开的？
    在公式中可以看到，每个因子都只计算了一个词出现的概率，所以每一步只能生成一个词；并且下一个词依靠的是上面出现过的词，所以生成任务是逐词展开的。
-   [Chain of Thought (CoT) 1]是一种用于增强**大语言模型推理能力**的**提示工程技术**，通过引导模型**一步步推理**来提高其在多步逻辑任务中的表现，如数学题、常识推理、符号逻辑等。Test-Time Scaling（或称为“推理时扩展”、“部署时扩展”）通常指**在不重新训练模型的情况下，通过外部机制提升大语言模型（LLM）在测试阶段的性能**，如**检索增强（RAG）**。
    -   找一道较难的高等数学题目，和类似题目及其答案。再找一个任意具有检索功能的LLM网页版服务。
    -   请对比直接输出答案（zero-shot）与使用 CoT 提示（few-shot CoT）的输出区别，并解释原因。
    直接输出答案不会展示思考过程；CoT即让LLM展示出逐步思考的过程，相当于**深度思考**的功能，可以让用户看到AI像人类一样从拿到问题到解决问题的思路，也方便检查。CoT（Chain-of-Thought）,即思维链提示，**通过给大模型提供中间推理步骤的实例，来显著提升其复杂推理能力**。通过“输入->分步推理->答案”的三元组来替代传统“输入->答案”的提示方式，就像“把思考过程一步一步写出来”。
    -   请对比使用不使用 RAG 和使用 RAG 的输出区别，并解释原因。
    RAG，检索增强生成，RAG会**从外部知识库中检索相关内容**，然后将检索到的内容与用户的问题一起当做上下文，然后让大模型基于这些上下文做出回答。使用RAG会**实时获取最新信息**，并且幻觉率会降低（基于实际检索内容生成，不会胡编乱造）。原因在于。不使用RAG仅靠模型预训练记忆，而使用RAG可以实时检索外部知识库+预训练记忆；并且，使用RAG基于实际检索内容生成，出现虚假的答案概率降低。
-   [LLM Mathematical Reasoning with Lean4 1]
    -   Lean4是什么？这篇工作为什么要用 Lean4？
    Lean4是**计算机形式化证明语言**的最新版本，是一种兼具函数式编程语言特性与数学形式化证明能力的工具。使用它是因为**Lean4语法很简洁**，避免了大语言模型学习形式化证明的语法障碍；存在高质量纯Lean4代码库，包含10万个人工编写的数学定理证明，为该工作生成“自然语言-形式语言对齐数据”提供了充分的素材。
    -   本文的数据集是如何生成的？包含什么内容？
    本节介绍自然语言（NL）-形式语言（FL）对齐数据集生成方法。如前所述，我们选择Lean4作为研究中的形式语言。**从数据集角度来看，数据集生成的目的是提升大型语言模型的定理证明能力**。据我们所知，目前开源的Lean4自然语言-形式语言对齐数据集规模均不超过1000条记录，而我们生成的开放自举定理集（OBT）包含106,852条自然语言-形式语言对齐且经过自举的定理。
    随着现代大语言模型的发展，他们提出了一种为MathLib4生成自然语言-形式语言对齐数据集的方法，这种**从形式证明编写非形式证明的方法被称为形式化逆过程**。具体而言，先微调ByT5编码器，使自然语言陈述和Lean4的代码的余弦相似度对齐；随后，使用该编码器对Mathlib4中的Lean4定理陈述和一个小型自然语言-形式语言对齐数据集中的非形式化定理陈述进行编码；非形式化处理后，进行初步的数据质量检查.
    他们发现，由于自然语言推理和Lean4定理证明之间存在显著差异，**仅依靠外部自然语言指导的训练数据，不足以让大型语言模型具备强大的Lean4定理证明能力**。大型语言模型常常会偏离证明思路，反复生成最终的Lean4策略。受大型语言模型编码研究（Song等人，2024）的启发——在编码任务描述中加入自然语言注释能大幅提升大型语言模型编码器的性能，提出了创新的**自然语言-形式语言自举方法**。
 我们通过向Gemini提供定理的自然语言和形式语言版本，让它**通过注释的方式将自然语言证明记录到Lean4代码中**，从而实现这种整合。为确保自举后数据的正确性，我们运行了一个**检查算法：删除生成代码中的所有注释，并确保其与原始代码一致。**
    -   本文怎么克服自然语言推理与 Lean4 形式化推理之间的壁垒的？
    这种**自举方法**旨在降低对大型语言模型而言复杂且陌生的Lean4形式语言推理与自然语言推理之间的门槛。我们发现，大多数现代大型语言模型都具备较强的自然语言推理能力，但对形式推理并不熟悉。**通过对数据集进行自举，该方法能帮助大型语言模型将自然语言推理能力迁移到Lean4定理证明中，促使大型语言模型同时进行形式推理和非形式化推理**。使用经过自举的数据集训练的大型语言模型，将学会更好地利用自然语言步骤来指导Lean4证明的编写。通过上述生成和自举方法，我们得到了用于训练大型语言模型的**开放自举定理集（OBT）**。
    通俗来说，LLM虽然很擅长自然语言推理，但是对Lean4这种形式语言很陌生。所以自举方法通过**在形式化语言证明中插入自然语言注释**，相当于让自然语言指导模型完成形式化证明。
    -   本文的训练过程是怎样的？除了推理的时候，还有哪些地方用到了 LLM？
    1 块训练块训练：利用上下文学习能力，将训练数据组织为文本环，填充上下文示例，增强LLM对Lean4的上下文理解。
    2 课程数据排序：按证明难度排序训练数据，使LLM从简单到复杂学习，稳定训练过程。
    3 指令微调：使用块训练和课程排序在OBT数据集上微调Llama3-8B-Instruct，训练LLM利用NL推理编写Lean4证明。
    4 迭代证明：写作利用之前生成的正确证明作为上下文示例，迭代提升LLM证明能力，减少分布差异。
    数据集构建：Gemini-1.5把lEAN4代码翻译成自然语言；
    示例检索：ByT5-Tacgen对自然语言定理和Lean代码做语义对齐；
    数据自举：插入自然语言注释；
    迭代写作：利用训练好之后的**TheoremLlama**用自生成的语言继续学习。
    以上模块都用到了LLM。
### 提交说明
-   文件夹命名为“task4”，内容一并放在 GitHub 上，文件夹中应包含：
-   **文档**：你的学习笔记、实验过程的记录、验证结果截图等。
-   你的所有**代码**，及其 readme 文件。
<!--stackedit_data:
eyJoaXN0b3J5IjpbNTE3OTUzMjgzXX0=
-->
