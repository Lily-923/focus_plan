## 原论文精读
### 导言
 基于纯注意力机制的Transformer模型和RNN相比：
 1.RNN输出的每一个词，是基于当前的词t和上一个词h(t)（包含了历史信息）,也就说明了RNN必须做时序计算而**无法并行计算**；
 2.深度RNN可能会丢失早期的信息
### 相关工作
 1.基于纯注意力机制的Transformer模型一次可以看到所有的像素，而CNN只能关注局部特征；
 2.CNN的多个输出通道可以同时关注图像的多个特征，基于这一点Transformer模型提出了**多头注意力机制**模拟CNN多输出通道的效果
 3.自注意力机制
 4.Transformer模型是第一个**只基于纯注意力机制**，来做编码器/解码器的模型
### 模型
![输入图片说明](https://github.com/Lily-923/stackedit-app-data/blob/master/imgs%252F2025-09-28%252FwNZS1q3KT9GLj5Oc.png)
#### 编码器的架构
分成两个子层(sub-layer)：Multi-Head Attention和Feed Forward（可以看做是一个MLP），加上一些残差连接
#### LayerNorm和batchnorm
![输入图片说明](https://github.com/Lily-923/stackedit-app-data/blob/master/imgs%252F2025-09-28%252FwJn0KWf0NMfoCEnN.png)
归一化：让样本数据范围大小大致相同，使得在运行梯度下降算法是比较容易振荡到全局最优。
BatchNorm：批归一化。在一个批次里，针对某一个特征，对所有样本进行归一化处理。但是在RNN/Transformer这种序列长度变化的模型中，**每个样本的序列长度可能不同**，BN难以应用。（适用于CNN：计算方式和输出参数的量是可以由卷积（过滤器）的相关参数预测的。无论输入什么内容的图片，经过相同的卷积层，得到输出图片的尺寸大小一定相同。与输入内容无关）
LayerNorm：层归一化。针对一个样本的所有特征进行归一化处理，适用于动态网络。（RNN/Transformer:他们的计算路径依赖于输入内容，历史信息）
#### 解码器
在解码器训练的时候， 在t时刻不应该看到t时刻以后的输入（自回归），但是在Transformer中一次性可以看到所有的输入，所以这里开始使用了一个**带掩码的多头注意力机制**。
**在任何一个训练序列的模型中，当预测下一个词时，模型都只能看已经出现的信息（即历史信息），而不能看到未来的信息。**
#### Attention注意力机制
value:值
key:关键词
query:查询
根据向量内积计算query和key的相似度，比如给你一个query向量，那么就计算它和n个value向量的内积，然后把结果做一个softmax函数得到n个加起来等于1的权重。再把这n个权重乘以对应的value值相加得到结果。
我们肯定要**利用矩阵并行计算**：
![输入图片说明](https://github.com/Lily-923/stackedit-app-data/blob/master/imgs%252F2025-09-28%252FrrfPQtlwJIKNt2rT.png)
n*m矩阵：**刻画每一个query向量和key向量相似度的一个矩阵**。得到这个矩阵后每一行，每一行再softmax函数（按照行做softmax,是根据每一个query对于一共m个k向量的相似程度，应该有m个权重值。），就是一个和为1的输出，乘以value矩阵得到结果。
dk的作用：当Q/K的维度（dk）比较大的时候（Transformer里面一般都比较大），  有可能存在一些比较大的值，使得向量点乘出来的值很大，导致**softmax函数输出的值两极化**。而这使得梯度下降函数没得学了（因为我们希望的结果是可行的地方尽量靠近1，不可行的尽量靠近0。这时模型就会跑不动）。除以这个数，可以有效地解决这个问题。
#### Mask
其实就是在计算第t个value值的时候，把后面的值屏蔽，只看前面t-1个value1.
通过把后面的元素的值的指数部分设置成一个非常大的负数，可以得到后面值的权重基本上为0，只利用了前面的计算结果。
#### Muti-Head Attention
![输入图片说明](https://github.com/Lily-923/stackedit-app-data/blob/master/imgs%252F2025-09-28%252FN9Xgc59X75zyUgPo.png)
![输入图片说明](https://github.com/Lily-923/stackedit-app-data/blob/master/imgs%252F2025-09-28%252FGAhW1OmuL0uoE9bl.png)
多头注意力，就是**模拟了CNN中多个输出通道**的感觉。
我们看上面的右图：首先通过一个可以学习到的**矩阵W**，把三个矩阵Q/K/V投影到一个低维度空间（线性层liner），在实现多次的点乘注意力机制（也就是作为上面Attention部分的输入，这里图中是h次）之后，整合成一个向量，最后通过线性层（liner）输出。我们希望在多次的输入中可以学习优化这个投影的W矩阵，**可以学习到不同的投影的方法**，从而应对不同的语境。
在上面的左图中不难看出，单个的注意力函数中，没有什么可以学习的参数，因为计算过程就是做内积。
#### 注意力机制在Transformer中的使用 
1.编码器中第一个注意力层的使用：
我们把三个矩阵，Q/K/V复制成三个一样的矩阵，对应图中的三个箭头。也就是说，我们根据Q和K之间的相似度，计算出V的权重和，**实际上是在计算V自己和其他词之间的相似度，也就是自注意力机制/双向注意力机制。这里就相当于编码器在理解和浓缩整个序列的信息，为解码器提供一个全面的上下文表示。相当于我们翻译句子的时候，首先得通读句子，理解整个句子的含义。**
这里的Q和V矩阵经过线性变换得到，通常不同。
![输入图片说明](https://github.com/Lily-923/stackedit-app-data/blob/master/imgs%252F2025-09-28%252FO27v70Po92Ko5N7n.png)
2.解码器中的第一个注意力层：其实和上面很相似。只是这里使用了Mask。
为什么这里要使用掩码？
上面已经说过任何解码器都应该保证**自回归性**。这里的解码器的第一个注意力层就保证了自回归性：
我们可以这样理解，**这里的每一个位置上的Q向量都在问：基于目前已经生成的目标序列，我应该从编码器给我提供的源序列中，关注哪些部分来帮助我生成下一个词？**
![输入图片说明](https://github.com/Lily-923/stackedit-app-data/blob/master/imgs%252F2025-09-28%252FQb99kCOOX115DV1b.png)
3.解码器的第二个注意力层：
首先，编码器的输出是n个长度为d的向量（这个是自注意力机制的输出，因此反映了输入的语句中，每个词语和其他词语的相似程度）；解码器的输出是m个长度为d的向量。
编码器的输出作为K和V输入（**我们已经通读了全文（中文），提取出了有效信息。**），解码器的输出作为Q输入（**现在读到这里了，下面应该是和原来的中文中的哪一个词相关呢？**） ，那么我的输出就是编码器中的V（**拿着刚刚提出的问题，根据K/V寻找出答案：最终找到了我们想注意的那个单词）另一种语言，例如中文） **）的一系列加权和。
关于Attention如何在编码器和解码器之间传递信息：根据解码器当前的输出不同，挑选编码器中我可能感兴趣的词语/注意到我会感兴趣的词语/我想要注意的词语。
为什么叫做**注意力机制**也就在于这里：
为什么在Transformer模型里，有效的信息可以通过计算单词之间的相似度来表达？我觉得这个应该和人类理解过程中的**语境**相似。单词之间的相似度就代表了文章中上下文（就拿中文翻译成英文举例。）的语境。编码器中输出的K矩阵通过计算每个单词和全文中所有单词的相似程度，就包含了全文的语境信息。解码器中第一层注意力层就是重新基于已经读到的内容，得到在前文中已知的原文中，我应该着重**关注注意**哪些词语来得到下一个词语？解码器的第二层注意力层就相当于基于前面提出的问题Q，在原序列K/V中找到对应的词语（结合全文语境，前面得到我想要关注的词语的权重就较大，其他的词语的权重就较小。）计算出权重和，也就是对应的下一个单词。
值得注意的是，在模型中整个过程在一个**跨语言的语义空间**里完成，从而不存在中文突然转化成英文，例如下面提到的embedding操作。
#### Feed-Forward NetWorks
实际上就是单隐藏层的MLP  ，把经过注意力层的，已经提取出信息的向量，把每个输出映射到想要的语义空间中。
对比一下RNN和Transformer是怎么有效使用序列信息：
前者是将上一时刻的输出作为历史信息，输入到下一层中；而后者是通过一个注意力层来全局利用整个序列的信息。
![输入图片说明](https://github.com/Lily-923/stackedit-app-data/blob/master/imgs%252F2025-09-28%252FfKcUuQPI2M0TAiAr.png)
#### Embeddings and Softmax
 Embeddings:就是把输入的单词，整合成一个向量。
#### Positional Encoding
由于Attention是**不含有时序信息**的：每一个输出是对输入Value的一个加权和，而决定加权和的是当前Q和K的相似程度。如果我把输入的N个向量完全打乱顺序，得到的输出仍然不变。
在RNN里面是把上一时刻的输出作为历史信息，输入到下一层中来包含时序信息的。
Positional Encoding干的就是在输入Attention层之前，把时序信息加入输入的过程。具体计算是利用了**cos/sin**函数完成的。

## 贪心搜索和束搜索
![输入图片说明](https://github.com/Lily-923/stackedit-app-data/blob/master/imgs%252F2025-09-29%252F13RSl8BJx2WNCNSi.png)
![输入图片说明](https://github.com/Lily-923/stackedit-app-data/blob/master/imgs%252F2025-09-29%252FXpQXvzYn0RAq8hWS.png)
![输入图片说明](https://github.com/Lily-923/stackedit-app-data/blob/master/imgs%252F2025-09-29%252FpRAIGgzQiSHymxVy.png)

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTMxMTE1NzU3MF19
-->
