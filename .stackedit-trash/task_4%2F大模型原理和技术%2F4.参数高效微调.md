# 4-0参数高效微调简介
预训练模型难以直接匹配到下游任务。
上下文学习通过输入相关概念以及引导，可以一定程度下适配到下游任务。
但是上下文学习依赖于给出的的例子，**泛化性不强**。而且需要人工编写大量例子，输入给模型的token很多，导致推理效率变低。
指令微调：为了保证下游任务性能，语言模型需要定制化调整。
![输入图片说明](/imgs/2025-10-14/0elqpllVsaAlj3Va.png)
![输入图片说明](/imgs/2025-10-14/T4Tppt72SyUAKeiM.png)
全量微调有很多缺点：计算量大，效率低等等。
**参数**高效微调：只调参数仅保留部分参数，显著降低存储空间。同时保证微调性能不受影响。
![输入图片说明](/imgs/2025-10-14/wkUDynd4vtLYphWS.png)
参数高效微调的主要方法：
![输入图片说明](/imgs/2025-10-14/20o3nhvNM3V5t5E7.png)
# 4-1参数附加方法
![输入图片说明](/imgs/2025-10-14/9epQLPUEsBDSoAOd.png)
![输入图片说明](/imgs/2025-10-14/mfIbEfBZmdtNXEh3.png)
## 1,Prompt-tuning：只 把参数加到输入上![输入图片说明](/imgs/2025-10-14/CVUfK3dXJ3RkodP6.png)
## 2.加在模型
Prefix-tuning:在Prompt-tuning的基础上，附加参数在模型里面。
Adapter-tuning:在模型的各个模块增加新的模块，符合Transformer模块化设计的思想。
![输入图片说明](/imgs/2025-10-14/68yBaFO50qsfOKkz.png)
把参数加在模型上的优点：
![输入图片说明](/imgs/2025-10-14/AqJaTIi05tbRCYT2.png)
## 3.加在输出
那参数是否可以及其在输出上？
只把参加到输入和模型上，面对大规模模型可能会遇到黑盒问题（无法访问模型权重）/数据load不进等问题。
代理微调： 
![输入图片说明](/imgs/2025-10-14/1vV2WpQbJnUjVfGv.png)
![输入图片说明](/imgs/2025-10-14/dQVf4srYeRhJcntw.png)
将微调之后的小模型和微调之前的小模型的差异迁移到大模型上，实现了高效微调大模型。十分有前景。
![输入图片说明](/imgs/2025-10-14/PqHHcLuxz6RuKXFI.png)
# 4-2参数选择方法
选择出一部分的参数进行微调
1.基于规则选择
BitFit:仅优化神经网络中每一层的偏置项；只优化最后四分之一层的参数；只选择最小绝对值的参数......
2.基于学习选择
让模型自己学习选择那些参数。
参数选择方法应用不多，不是高效微调方法的主流。
# 4-3低秩适配方法
这也是目前用的最多的参数微调方法。
LoRA: 将参数矩阵分解为两个低秩矩阵，只学习这两个低秩矩阵。 
![输入图片说明](/imgs/2025-10-14/53Bp3hqkGkdpHjtI.png)
![输入图片说明](/imgs/2025-10-14/w6sNa2Le6G7C7yWj.png)
![输入图片说明](/imgs/2025-10-14/MQjRhzYgakpfwzCl.png)
相对于参数附加方法，LoRA不需要改变模型架构，是体外训练，具有**插件化特性**。
![输入图片说明](/imgs/2025-10-14/QBSYBuPYJQC9M4K3.png)
LoRA变体：
![输入图片说明](/imgs/2025-10-14/ehrPOiDRccwLgYeD.png)
LoRAHub:将多个LoRA插件根据不同的问题赋予不同的权重，相结合解决不同的问题。
![输入图片说明](/imgs/2025-10-14/advg4c4I5m6CJrZP.png)
显著节约了内存占用的QLoRA:
![输入图片说明](/imgs/2025-10-14/A7HjyfLenQxRSO5i.png)
提高并行操作性。 
![输入图片说明](/imgs/2025-10-14/Le3UpwASdIFpHcYD.png)
# 4-4参数高效微调（PEFT）的应用 
1.预训练
![输入图片说明](/imgs/2025-10-15/K7pNVjq4L3r5obxE.png)
2.连续学习：学了新任务忘了老任务。LoRA以插件形式储存；
3.医疗金融领域等
<!--stackedit_data:
eyJoaXN0b3J5IjpbMjA0NzA1MjkxNl19
-->